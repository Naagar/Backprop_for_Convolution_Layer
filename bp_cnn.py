# -*- coding: utf-8 -*-
"""BP_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10-2z_21k6Tf3VboUT4Odih4bDTecYh0b
"""

import torch.nn as nn
import torch
import numpy as np

"""## Solve for y from x and w
$$y = x * W$$
"""

n = 3 # input size
k = 3 # kernel size
m = nn.Conv2d(1, 1, k, bias=False, stride=1, padding="same") # define convolution layer using torch.nn
target = torch.randn(1, 1, n, n) # y
weight = np.random.randn(k,k)
m.weight = nn.Parameter(torch.FloatTensor(weight).reshape(shape=(1,1,k,k))).requires_grad_() # W
input = np.random.randn(n,n) # x
# input = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)
# convert numpy array to tensor
input_t = torch.from_numpy(input).float() 

# reshape input
input_t = input_t.reshape(shape=(1,1,n,n)).requires_grad_()

# m.bias = nn.Parameter(torch.zeros(1))
output = m(input_t)
# out =  target - output

# check the bias
m.bias

# define convolution operation / layer
def convolve(img: np.array, kernel: np.array, output_size: int) -> np.array:
    # Assuming a rectangular image
    # tgt_size = calculate_target_size(
    #     img_size=img.shape[0],
    #     kernel_size=kernel.shape[0]
    # )
    # To simplify things
    tgt_size = output_size
    k = kernel.shape[0]
    
    # 2D array of zeros
    convolved_img = np.zeros(shape=(tgt_size, tgt_size))
    
    # Iterate over the rows
    for i in range(tgt_size):
        # Iterate over the columns
        for j in range(tgt_size):
            # img[i, j] = individual pixel value
            # Get the current matrix
            mat = img[i:i+k, j:j+k]
            
            # Apply the convolution - element-wise multiplication and summation of the result
            # Store the result to i-th row and j-th column of our convolved_img array
            convolved_img[i, j] = np.sum(np.multiply(mat, kernel))
            
    return convolved_img

img_pad = np.pad(input, ((1, 1), (1, 1)), 'constant') # zero padding
# print(img_pad)

# convolution operation
output1 = convolve(img_pad, weight, output_size=n)

# Finding the loss 
loss_t = (output*output).sum()

print(output.shape, output1.shape)
print(output)
print(output1)

# Compare the coutput from torch.nn.Conv2d and Convolution operation
print(np.abs((output.detach().numpy()[0,0] - output1)).sum())

output1_mean = output1.sum()
output_mean = output.sum()

print('sum of the outputs (y):'output_mean, output_mean)

# loss/error = np.sum(output-image)

error1  = target - output1
error = target - output
L = (error1*error1)/2
dL_dy = 2*output1

# Calculating error for both outputs, they should be same.
print(error1.sum())
print(error.sum())

loss_t.backward() # backprop for nn.con2d

# dL_dy_pad = np.pad(dL_dy, 1, 'constant', 0)
# dL_dy_pad = np.pad(error1.detach().numpy()[0,0], ((1, 1), (1, 1)), 'constant', constant_values=((0,0), (0,0)))
# print(dL_dy_pad)

# print(weight)

# weight_rot
weight_rot = weight[::-1, ::-1]

"""$$ dL/dy = loss $$
$$ dL/dx = dL/dy * dy/dx $$
$$ dL/dw = dL/dy * dy/dw $$

"""

dL_dy_pad = np.pad(dL_dy, ((1,2),(1,1)), 'constant')
# weight_rot_pad= np.pad(weight_rot, ((2, 2), (2, 2)), 'constant')
# print(weight)
# dL_dy = 
print('/n')
print('dL/dx for torch.nn.Conv2d:', input_t.grad)
# dL_dy_2d = dL_dy
# print(dL_dy)
dL_dx = convolve(dL_dy_pad, weight_rot, output_size=n)
print('dL/dx for Convolution:', dL_dx)

# print(output.grad)

# error_pad = error1.detach().numpy()[0,0]
# error_pad = np.pad(error_pad, ((1, 1), (1, 1)), 'constant', constant_values=((0,0), (0,0)))
# img_pad2
# input_pad = np.pad(input, ((2, 2), (2, 2)), 'constant')
dL_dw = convolve(dL_dy_pad, input, output_size = 3)
# print(error1.detach().numpy()[0,0].shape)
print('dL_dw:', dL_dw)
print('m.weight.grad', m.weight.grad)

weight_grad = m.weight.grad.detach().numpy()[0,0]
weight_grad = weight_grad[::-1,::-1]
# print(weight_grad)
print('difference of two different weight gradients from torch.nn.Conv2d and Convolution:',np.abs((weight_grad - dL_dw)).sum())



































"""# Rough Work"""

print(W)

nn.Paramteters(torch.tensor(W))

W = np.ones(shape=(k,k)).reshape((1,1,k,k))

# print(output.grad_fn)
# loss = nn.CrossEntropyLoss()
# target = np.random.randn(n,n)
# target = torch.from_numpy(target)
# print(target.shape)
# output_ = loss(output, target)
# print(grad_in[1])

# def backward_hook(m, input_gradients, output_gradients):
#     print('input_gradients {}'.format(input_gradients))
#     print('output_gradients {}'.format(output_gradients))
#     input_gradients = (torch.ones_like(input_gradients[0]), )
#     return input_gradients

# conv = nn.Conv2d(1, 1, 3)
# conv.register_full_backward_hook(backward_hook)

# x = torch.randn(1, 1, 3, 3).requires_grad_()

# out = m(input_t)

# out =  target - output
# out.mean().backward()
 # ones # print the gradient using .grad
# # print("A.grad:", input_t.grad)

# loss = nn.CrossEntropyLoss()
# output_ = loss(target, output)

# loss_ =

# input = torch.randn(20, 2, 50, 50)

import cv2 
import numpy as np

class Conv_Module():
    def __init__(self, img, ker, b, pad=1, stride=1):            #initialization
        
        self.img_b, self.img_d, self.img_h, self.img_w=img.shape
        self.ker_b, self.ker_d, self.ker_h, self.ker_w=ker.shape
        self.b, self.pad, self.stride, self.img, self.ker=b, pad, stride, img, ker
        
    def __call__(self):                                      
        self.out=self.forward(self.img, self.ker)            #forward method is called with images, kernel as input
        return self.out
    
    def forward(self): raise Exception('Not Implemented')    #default raises not implemented error.
    def backward(self): return self.bwd(self.out)           #output from the forward method gets passed here as the input.





# input = np.arange(3,3)
# image = np.array([[1, 2, 3], [ 4, 5, 6], [7, 8, 9]])
# input = np.random.rand(5,5)

# input = np.array([[0, 0, 0, 0,0], [0, 1, 2, 3, 0], [0, 4, 5, 6, 0], [0, 7, 8, 9, 0], [0, 0, 0, 0, 0]])
# weight = np.array([[-1, -1, -1], [-1, 0, -1], [-1, -1, -1]]) #np.array([[1, 2], [3, 4]])
weight = m.weight.detach().numpy()[0,0]

import numpy as np
import matplotlib.pyplot as plt
img=np.random.rand(1, 1, 10,10)
ker=np.random.rand(1, 1, 3,3)

print(input.shape)
print(weight.shape)

m.weight.shape

# loss = np.sum(output-image)
dL_dy = 2*(input-output1)
print(dL_dy)

# dL/dy = 
# dL/dx =
# dL/dw =

m_test = torch.nn.Sigmoid()
loss_test = nn.BCELoss()
input_test = torch.randn(3, requires_grad=True)
target_test = torch.empty(3).random_(2)
output_test = loss_test(m_test(input_test), target_test)
output_test.backward()

output_test

input_test

target_test

m_test(input_test)

